{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch \n",
    "from sklearn.metrics import *\n",
    "import nltk \n",
    "from Marbert.Preprocessing import clean_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Marbert import BertClassifier\n",
    "from scipy.special import softmax\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "import keras \n",
    "import json\n",
    "from sklearn.model_selection import GridSearchCV as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    return ' '.join(word_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الاوليمبياد الجايه هكون لسه الكليه .</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عجز الموازنه وصل ل93.7 الناتج المحلي يعني لسه ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>كتنا نيله حظنا الهباب xD</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جميعنا نريد تحقيق اهدافنا تونس تالقت حراسه الم...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الاوليمبياد نظامها مختلف . ومواعيد المونديال م...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet    label\n",
       "0               الاوليمبياد الجايه هكون لسه الكليه .     none\n",
       "1  عجز الموازنه وصل ل93.7 الناتج المحلي يعني لسه ...    anger\n",
       "2                           كتنا نيله حظنا الهباب xD  sadness\n",
       "3  جميعنا نريد تحقيق اهدافنا تونس تالقت حراسه الم...      joy\n",
       "4  الاوليمبياد نظامها مختلف . ومواعيد المونديال م...     none"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Emotional-Tone-Dataset.csv')\n",
    "data.dropna(inplace=True)\n",
    "data.rename(columns={' TWEET':'tweet',' LABEL':'label'},inplace=True)\n",
    "data.drop(columns=['ID'],inplace=True)\n",
    "data['tweet'] = data['tweet'].astype(str)\n",
    "data['tweet'] = data['tweet'].apply(clean_text)\n",
    "data['tweet'] = data.tweet.apply(tokenize_data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Encoding Labels</h1>\n",
    "<span>same as MARBERT encoding</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoding_dict = {'none':0, 'anger':1, 'joy':2, 'sadness':3, 'love':4, 'sympathy':5, 'surprise':6, 'fear':7}\n",
    "data['label'] = data['label'].map(Encoding_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الاوليمبياد الجايه هكون لسه الكليه .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عجز الموازنه وصل ل93.7 الناتج المحلي يعني لسه ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>كتنا نيله حظنا الهباب xD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>جميعنا نريد تحقيق اهدافنا تونس تالقت حراسه الم...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الاوليمبياد نظامها مختلف . ومواعيد المونديال م...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0               الاوليمبياد الجايه هكون لسه الكليه .      0\n",
       "1  عجز الموازنه وصل ل93.7 الناتج المحلي يعني لسه ...      1\n",
       "2                           كتنا نيله حظنا الهباب xD      3\n",
       "3  جميعنا نريد تحقيق اهدافنا تونس تالقت حراسه الم...      2\n",
       "4  الاوليمبياد نظامها مختلف . ومواعيد المونديال م...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loading the Base Models<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n",
      "WARNING:tensorflow:From d:\\Python\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "BertClassifier.initializeModel(os.path.join(current_path,'ModelsFiles/bert_classifier_model.pth'),os.path.join(current_path,'ModelsFiles/tokenizer.pkl'))\n",
    "bertModel = BertClassifier.bertModel\n",
    "bertTokenizer = BertClassifier.berTokenizer\n",
    "biLstmModel = load_model('ModelsFiles/BiGRU_model.h5')\n",
    "biGruModel = load_model('ModelsFiles/BiLSTM_model.h5')\n",
    "tokenizer_config_file = \"ModelsFiles/tokenizer_config.json\"\n",
    "with open(tokenizer_config_file, 'r') as f:\n",
    "    tokenizer_config = json.load(f)\n",
    "tokenizer_json = json.dumps(tokenizer_config)\n",
    "bilstm_bigru_tokenizer = tokenizer_from_json(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE'S HOW TO REARRANGE ARRAY \n",
    "LSTM_GRU_MAP = [4,0,2,5,3,7,6,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test =  train_test_split(data['tweet'],data['label'],random_state=23,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LSTM_GRU_TRAIN = bilstm_bigru_tokenizer.texts_to_sequences(x_train.astype('str'))\n",
    "X_LSTM_GRU_TRAIN = keras.preprocessing.sequence.pad_sequences(X_LSTM_GRU_TRAIN, padding='post', maxlen=300)\n",
    "X_MARBERT_TRAIN = x_train\n",
    "LABELS_TRAIN = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 31s 121ms/step\n",
      "252/252 [==============================] - 87s 344ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_predictions = biLstmModel.predict(X_LSTM_GRU_TRAIN)\n",
    "gru_predictions = biGruModel.predict(X_LSTM_GRU_TRAIN)\n",
    "marbert_predictions = [BertClassifier.predict(tweet).detach().numpy() for tweet in X_MARBERT_TRAIN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span><i>in case if you need to save them \n",
    "</i></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"lstmpreds.npy\",lstm_predictions)\n",
    "np.save(\"grupreds.npy\",gru_predictions)\n",
    "np.save(\"bertpreds.npy\",marbert_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's inspect the marbert predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2781606 , -0.34234795,  0.14533697, -0.20055684, -0.83126587,\n",
       "       -0.86984384,  2.4719045 , -0.39631644], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marbert_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>Marbert Outputs are obviously not a softmax layer output, it's just the final layer of marbert, so we need to apply softmax to it in order to ensure consistency among all outputs,<br> and also the lstm and gru labels positions in the softmax output are not the same  as the marbert model's labels' positions so we need to reorder the indicies or the positions of both lstm and gru to ensure that every thing is coherent and consistent</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "marbert_predictions = np.squeeze(marbert_predictions)\n",
    "marbert_predictions = softmax(marbert_predictions,axis=1)\n",
    "for i in range(x_train.size):\n",
    "    lstm_predictions[i][:] = lstm_predictions[i][LSTM_GRU_MAP]\n",
    "    gru_predictions[i][:] = gru_predictions[i][LSTM_GRU_MAP]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>now everything is consistent with each other and all the outputs have the same format, let's go on to build the meta model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=50, random_state=23)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=23)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, random_state=23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_RF_TRAIN = np.concatenate([marbert_predictions,lstm_predictions,gru_predictions],axis=1)\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=50,random_state=23)\n",
    "random_forest_classifier.fit(x_RF_TRAIN,LABELS_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we're done, prepare the test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LSTM_GRU_TEST = bilstm_bigru_tokenizer.texts_to_sequences(x_test.astype('str'))\n",
    "X_LSTM_GRU_TEST = keras.preprocessing.sequence.pad_sequences(X_LSTM_GRU_TEST, padding='post', maxlen=300)\n",
    "X_MARBERT_TEST = x_test\n",
    "LABELS_TEST = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 9s 133ms/step\n",
      "63/63 [==============================] - 23s 349ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_predictions = biLstmModel.predict(X_LSTM_GRU_TEST)\n",
    "gru_predictions = biGruModel.predict(X_LSTM_GRU_TEST)\n",
    "marbert_predictions = [BertClassifier.predict(tweet).detach().numpy() for tweet in X_MARBERT_TEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "marbert_predictions = np.squeeze(marbert_predictions)\n",
    "marbert_predictions = softmax(marbert_predictions,axis=1)\n",
    "for i in range(x_test.size):\n",
    "    lstm_predictions[i][:] = lstm_predictions[i][LSTM_GRU_MAP]\n",
    "    gru_predictions[i][:] = gru_predictions[i][LSTM_GRU_MAP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RF_TEST = np.concatenate([marbert_predictions,lstm_predictions,gru_predictions],axis=1)\n",
    "rf_predections = random_forest_classifier.predict(X_RF_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 5 ... 3 7 3]\n"
     ]
    }
   ],
   "source": [
    "print(rf_predections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENSEMBLE MODELING ACCURACY :  88.37555886736214 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(rf_predections,LABELS_TEST)\n",
    "print(\"ENSEMBLE MODELING ACCURACY : \" , accuracy*100 ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 5, ..., 3, 7, 3], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_TEST = np.array(LABELS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 5, ..., 3, 7, 3], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grf_predections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.84      0.87      0.85       321\n",
      "       anger       0.89      0.90      0.90       269\n",
      "         joy       0.89      0.81      0.85       266\n",
      "     sadness       0.80      0.87      0.84       243\n",
      "        love       0.88      0.91      0.89       249\n",
      "    sympathy       0.97      0.95      0.96       214\n",
      "    surprise       0.86      0.79      0.82       209\n",
      "        fear       0.98      0.97      0.98       242\n",
      "\n",
      "    accuracy                           0.88      2013\n",
      "   macro avg       0.89      0.88      0.89      2013\n",
      "weighted avg       0.89      0.88      0.88      2013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics._classification import classification_report\n",
    "labels = ['none', 'anger', 'joy', 'sadness', 'love', 'sympathy', 'surprise', 'fear']\n",
    "print(classification_report(y_true= LABELS_TEST,y_pred=rf_predections,target_names=labels,zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
