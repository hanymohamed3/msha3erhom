import string
import re
from .stopwords import stop_words_ar
arabic_punctuations = '''`√∑√óÿõ<>_()*&^%][ŸÄÿå/:"ÿü.,'{}~¬¶+|!‚Äù‚Ä¶‚Äú‚ÄìŸÄ'''
english_punctuations = string.punctuation
punctuations_list = arabic_punctuations + english_punctuations

arabic_diacritics = re.compile("""
                             Ÿë    | # Tashdid
                             Ÿé    | # Fatha
                             Ÿã    | # Tanwin Fath
                             Ÿè    | # Damma
                             Ÿå    | # Tanwin Damm
                             Ÿê    | # Kasra
                             Ÿç    | # Tanwin Kasr
                             Ÿí    | # Sukun
                             ŸÄ     # Tatwil/Kashida
                         """, re.VERBOSE)

arabic_handles = \
    [
        ('Ÿá', ['ÿ©']),\
        ('Ÿä', ['Ÿâ']),\
        ('ÿß', ['ÿ£','ÿ•','ÿ¢']),\
        # ('Ÿà', ['ÿ§']),\
        ('', ['Ÿë','‚Äò','Ÿå','Ÿè','Ÿã','Ÿé','Ÿê','Ÿç','ŸÄ','‚Äô','Ÿí','~'])
    ]

############### functions ##################
def clean_text(text):
    """
    It includes these functions:
        1-remove_emails
        2-remove_URLs
        3-remove_mentions
        4-hashtags_to_words
        5-remove_punctuationsb
        6-normalize_arabic
        7-remove_diacritics
        8-remove_repeating_char
        9- remove newlines
        10-remove_stop_words
        11-remove_emojis
        12-remove_english_characters
        13-remove_digits
    """

    text=remove_emails(text)
    text=remove_URLs(text)
    text=remove_mentions(text)
    text= hashtags_to_words(text)

    # Fihom moshkla
    # text=remove_punctuations(text)
    # text=normalize_arabic(text)
    # text=remove_diacritics(text)
    # text=remove_english_characters(text)
    # text=remove_digits(text)

    text=remove_stop_words(text)
    text= remove_newlines(text)
    text=remove_repeating_char(text)
    text=replace_emojis(text)

    return text


def normalize_arabic(text):
    """ normalize the arabic character  ."""
    text = re.sub("[ÿ•ÿ£ÿ¢ÿß]", "ÿß", text)
    text = re.sub("Ÿâ", "Ÿä", text)
    text = re.sub("ÿ§", "ÿ°", text)
    text = re.sub("ÿ¶", "ÿ°", text)
    text = re.sub("ÿ©", "Ÿá", text)
    text = re.sub("⁄Ø", "ŸÉ", text)
    return text


def remove_digits(word_list):
    # Remove digits
    filtered_words = ''.join([w for w in word_list if not w.isdigit()])
    return filtered_words

def remove_diacritics(text):
    """ remove the `arabic diacritics` from the `text` ."""
    text = re.sub(arabic_diacritics, '', text)
    return text


def remove_punctuations(text):
    """ remove the `punctuations` from the `text` ."""
    translator = str.maketrans('', '', punctuations_list)
    return text.translate(translator)


def remove_repeating_char(text):
    """ remove the `repeating character` from the `text` ."""
    return re.sub(r'(.)\1+', r'\1', text)

def remove_newlines(text):
  text = re.sub('\n'," . ",text)
  return text

def read_stop_words():
    """ read the `stopwords` """
    stop_words = stop_words_ar.split('\n')
    #unify arabic letters
    for key, arr in arabic_handles:
        for a in arr:
            stop_words = [word.replace(a, key) for word in stop_words]
    return stop_words

def remove_english_characters(text):
    # Define a regular expression pattern to match English characters
    english_pattern = re.compile("[a-zA-Z]")

    # Use sub to replace English characters with an empty string
    cleaned_text = english_pattern.sub('', text)

    return cleaned_text

def remove_stop_words(text):
    """ remove the `list of Arabic stopwords` from the `text` ."""
    stop_words = read_stop_words()
    lines = text.splitlines()
    new_lines = []
    for line in lines:
        if line.strip():  #if not empty
            words = line.split()
            for w in range(0, len(words)):
                word = words[w]
                if word in stop_words:
                    words[w] = ""
            line = " ".join(words)
            line = line.replace("  "," ")
            new_lines.append(line)
    return '\n'.join(new_lines)

def remove_URLs(text):
    """ remove the `URLs` from the `text` ."""
    text =re.sub(r"(?:http?\://|https?\://|www)\S+", "", text)
    return text

def remove_emails(text):
    """ remove the `emails` from the `text` ."""
    text = re.sub(r'[\w\.-]+@[\w\.-]+',"",text)
    return text

def remove_mentions(text):
    """ remove the `mentions` from the `text` ."""
    text = re.sub(r"@([A-Za-z0-9_-]+)", "", text)
    return text

def hashtags_to_words(text):
    """ convert any `hashtags` to  `words` ."""
    text = re.sub(r'#', "", text)
    text = re.sub(r"_", "  ", text)
    return text

def replace_emojis(text):
    text = re.sub(r'<3|< 3|‚ù§Ô∏è|üíñ|üòç|üíï|üòò|ü•∞|üíï|üíù|üíó|üíú|üíô|üñ§|üíö|üíõ|ü§ç|‚ù§',
                  ' ŸÇŸÑÿ® ',
                  text)

    text = re.sub(r':P|:-P|üòÇ|ü§£',
                  ' ÿ∂ÿ≠ŸÉ ',
                  text)

    text = re.sub(r'[‚ò∫üòåüòÅüòÉüòÑüòÜüòäüò∏üò∫üòäüòÄüòã‚ò∫Ô∏èüôÇüíÉ]',
                  ' ÿ≥ÿπÿßÿØÿ© ',
                  text)


    text = re.sub(r':D',
                  ' ÿ≥ÿπÿßÿØÿ© ',
                  text)

    text = re.sub(r'[üò•üò£üòìüòîüòï‚òπÔ∏èüôÅüòñüòûüòüüò¢üò≠üò©üòøüò´üò©üíî]',
                  ' ÿ≠ÿ≤ŸÜ  ',
                  text)
    text = re.sub(r'(::|\)-:)',
                  '  ÿ≠ÿ≤ŸÜ  ',
                  text)
    text = re.sub(r'(:,\(|:\'\(|:"\()',
                  ' ÿ≠ÿ≤ŸÜ ',
                  text)

    text = re.sub(r'[üò®üò±üòµ]',
                  ' ŸÖŸÅÿßÿ¨ÿ£ÿ© ',
                  text)

    text = re.sub(r'[üò≥üòÖüôà]',
                  ' ŸÖÿ≠ÿ±ÿ¨ ',
                  text)

    text = re.sub(r'[üò§üò†üò°ü§¨üëø]',
                  ' ÿ∫ÿ∂ÿ® ',
                  text)

    text = re.sub(r'[üòëüòíüôÑüòêüò∂]',
                  ' ŸÖŸÑŸÑ ',
                  text)

    text = re.sub('[\U0001F600-\U0001FFFF]'," ", text)
    text = re.sub('[\U0001F300-\U0001F5FF]'," ", text)
    text = re.sub('[\U0001F680-\U0001F6FF]'," ", text)
    text = re.sub('["\U0001F1E0-\U0001F1FF]'," ", text)


    weirdPatterns = re.compile("["
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               u"\U0001f926-\U0001f937"
                               u'\U00010000-\U0010ffff'
                               u"\u200d"
                               u"\u2640-\u2642"
                               u"\u2600-\u2B55"
                               u"\u23cf"
                               u"\u23e9"
                               u"\u231a"
                               u"\u3030"
                               u"\ufe0f"
                               u"\u2069"
                               u"\u2066"
                               u"\u200c"
                               u"\u2068"
                               u"\u2067"
                               "]+", flags=re.UNICODE)
    text = weirdPatterns.sub(r'', text)
    return text